\documentclass[11pt,a4paper,twocolumn,notitlepage]{article}

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{hyperref}

\begin{document}

\title{ODD for the decision-making model}
\author{Xavier Rubio-Campillo \and Mark Altaweel \and C. Michael Barton \and Enrico R. Crema}
\maketitle

\section{Purpose}

This model illustrates how ABM can be used to explore decision making in the context of a heterogeneous environment. In particular, we will examine how variations in agents' mobility can produce the emergence of a tragedy of the commons~\citep{hardin1968tragedy}.

TODO: reference paper?

\section{Entities, state variables, and scales}
\subsection{Agents}

Each agent is defined by a spatial location $x,y$, its current level of $energy$ and the $energyCost$ it consumes every time step.

\subsection{Environment}

Agents move within a spatial grid with dimensions $xDim \times yDim$. The grid represents a heterogeneous resource landscape where the cell in each set of coordinates $x,y$ is defined by the current level of resources it contains $resources$ and a maximum level $maxResources$. 

\section{Process overview and scheduling}

The simulation proceeds with a discrete number of time-steps, each where the following process updates the population of agents and the resources in the environment.

\begin{enumerate}
\item{Decision making}
\item{Collection}
\item{Cloning}
\item{Energy expenditure}
\item{Resource growth}

The order of agents' execution is shuffled every time step, and each phase is simultaneously executed for all agents before moving to the next one.

\end{enumerate}

\section{Design concepts}

\subsection{Basic principles}

The basic principles for this model are agents exist in a landscape of cells whereby they attempt to obtain resources from these cells. Cell resources grow at constant rates, while agents are able to view some distance within a space and can move to areas where they seem benefit in consuming resources from cells.

\subsection{Emergence}

Tragedy of the commons will emerge from the system if all agents have access to the same environmental information (i.e. high $radius$ values). In other words, agents are likely to over consume if they see the entire space or simulated region.

\subsection{Adaptation}

Agents do not adapt.

\subsection{Objectives}

The objective of each agent is to collect the highest value of $resources$ per time step.

\subsection{Learning}

Agents do not learn.

\subsection{Prediction}

Agents do not predict.

\subsection{Sensing}

Agents sense  $resources$ within a neighbourhood of Chebyshev distance $radius$. %We might consider the name to something like searchNeighbourhood or something.

\subsection{Interaction}

Agents directly interact with environment collecting $resources$. Competition between agents indirectly emerge from resource exploitation. 

\subsection{Stochasticity}

Stochastic elements include the initial  distribution of resources and agents,  the order of execution of agents, and the choice of cell to move if two (or more) cells have maximum $resource$ value in the search neighbourhood. 

\subsection{Collectives}

Agent operate independently. 

\subsection{Observation}

The number of agents is calculated at each time-step.

\section{Initialization}

These are provided in the main text and in the model input files included in each model. A parameter sweep is applied to a search radius for cell resources, whereby this parameter is varied for agents.

\subsection{Agents}

This model is initially populated by $nAgents$ located at random spatial coordinates.

\subsection{Environment}

The value of $maxResources$ of each cell is sampled from a uniform distribution $U(0,maxEnergy)$. Current $resources$ of each cell is then copied from its $maxResources$ value.

\section{Input data}

The model uses data files, which are included in the git repository for the models.

\section{Submodels}

\subsection{Decision making}

All agents move to a new location based on a greedy decision making process: each agent will move to the cell with highest resources within $radius$ of its current location $x,y$. Chebyshev distance is used to define the list of candidates (i.e. the greatest distance of the two dimensions, $x$ and $y$). %I think this definition is a bit confusing? Maybe a figure?

\subsection{Collection}

All agents collect resources up to $maxEnergy$ and the collected amount is removed from cell's $resources$. 

\subsection{Cloning}

Agents whose $energy$ equals $maxEnergy$ produce offspring. These have the same spatial location $x,y$ than their parents, and the $energy$ of both (parent and offspring) is updated to $energy = maxEnergy/2$.

\subsection{Energy expenditure}

Agents decrease their $energy$ level by $energyCost$. Offpsring do not decrease their $energy$ levels the time step they are created. If $energy \leq 0$ the agent dies and is removed from the simulation.

\subsection{Resource growth}

The $resources$ of each cell will increase every time step by the parameter $resourceGrowthRate$ up to the local $maxResources$.

\section{References}
\bibliographystyle{apalike}
\bibliography{references}

\end{document}

